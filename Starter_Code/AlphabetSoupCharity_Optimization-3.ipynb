{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ede5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 80)                3520      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5161 (20.16 KB)\n",
      "Trainable params: 5161 (20.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "804/804 [==============================] - 0s 328us/step - loss: 0.5718 - accuracy: 0.7212\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 0s 320us/step - loss: 0.5555 - accuracy: 0.7285\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 0s 320us/step - loss: 0.5520 - accuracy: 0.7314\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 0s 320us/step - loss: 0.5505 - accuracy: 0.7300\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 0s 319us/step - loss: 0.5499 - accuracy: 0.7317\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 0s 318us/step - loss: 0.5477 - accuracy: 0.7317\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 0s 319us/step - loss: 0.5478 - accuracy: 0.7334\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 0s 319us/step - loss: 0.5467 - accuracy: 0.7336\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 0s 319us/step - loss: 0.5463 - accuracy: 0.7338\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 0s 318us/step - loss: 0.5462 - accuracy: 0.7337\n",
      "Epoch 11/100\n",
      "315/804 [==========>...................] - ETA: 0s - loss: 0.5536 - accuracy: 0.7287"
     ]
    }
   ],
   "source": [
    "# Import our dependencies \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "# Import and read the charity_data.csv. \n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\") \n",
    "application_df.head()\n",
    "\n",
    "application_df.drop(columns=['EIN','NAME'], inplace=True) \n",
    "application_df.head()\n",
    "\n",
    "application_df.nunique()\n",
    "\n",
    "type_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
    "type_counts\n",
    "\n",
    "application_types_to_replace = list(type_counts[type_counts<500].index)\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "application_df['APPLICATION_TYPE'].value_counts()\n",
    "\n",
    "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
    "classification_counts\n",
    "\n",
    "classification_counts[classification_counts.values>1]\n",
    "\n",
    "classifications_to_replace = list(classification_counts[classification_counts<1000].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df['CLASSIFICATION'].value_counts()\n",
    "\n",
    "numeric_dummies = pd.get_dummies(application_df)\n",
    "numeric_dummies.head\n",
    "\n",
    "# Split our preprocessed data into our features and target arrays\n",
    "X = numeric_dummies.drop('IS_SUCCESSFUL', axis=1).values\n",
    "y = numeric_dummies['IS_SUCCESSFUL'].values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "input_features = len(X_train[0])\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "layer1_nodes = 80\n",
    "layer2_nodes = 20\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units = layer1_nodes, activation ='relu', input_dim = input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units = layer2_nodes, activation ='relu'))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units = 1, activation ='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()\n",
    "\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs= 100)\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "nn.save('../Deep_Learning/HDF5_Files/third_attempt.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3892e181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
